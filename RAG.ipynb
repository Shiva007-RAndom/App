{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM88XwfukLPDW1oBRnU4NjN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shiva007-RAndom/App/blob/main/RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "glyp6kPgNSUt",
        "outputId": "84229259-cb1f-45f8-b33c-c43819a5ec90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.63)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.25)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.43)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain_community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain_community) (2.11.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain_community) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain_community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
            "Downloading langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain_community-0.3.24 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.9.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sWh4T0YiNmZf",
        "outputId": "2295f097-1bf7-4511-b89b-a11824a8fc38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rank_bm25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "w77vBPEDNpw6",
        "outputId": "0a4b8090-f305-472b-b7ee-8663726495b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rank_bm25) (2.0.2)\n",
            "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Installing collected packages: rank_bm25\n",
            "Successfully installed rank_bm25-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOFazRtcu2ND"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/rag_sample_qas_from_kis.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import DataFrameLoader\n",
        "doc_loader = DataFrameLoader(df, page_content_column=\"ki_text\")\n",
        "doc = doc_loader.load()"
      ],
      "metadata": {
        "id": "k9XKrHMB0XeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000)\n",
        "chunks = text_splitter.split_documents(doc)"
      ],
      "metadata": {
        "id": "ApvcByFZ2ypd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "def faiss(query):\n",
        "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "  vecstore = FAISS.from_documents(chunks, embeddings)\n",
        "  faretriever = vecstore.as_retriever()\n",
        "  faresult = vecstore.similarity_search_with_score(query,k=3)\n",
        "  faresult = [(doc[0],1-doc[1]) for doc in faresult]\n",
        "  return faresult"
      ],
      "metadata": {
        "id": "nBPY45WOIKN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rank_bm25 import BM25Okapi\n",
        "def BM25(query,chunks):\n",
        "  words = [chunk.page_content.split(\" \") for chunk in chunks]\n",
        "  bm25 = BM25Okapi(words)\n",
        "  query_tokens = query.split(\" \")\n",
        "  scores = bm25.get_scores(query_tokens)\n",
        "  chunks_with_scores = [(chunks[i], scores[i]) for i in range(len(chunks))]\n",
        "  chunks_with_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "  return chunks_with_scores[:3]"
      ],
      "metadata": {
        "id": "hMY8HHrPJt1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Normalize(chunk_scores):\n",
        "  max_score = chunk_scores[0][1]\n",
        "  chunk_scores = [(chunk, score/max_score) for chunk, score in chunk_scores]\n",
        "  return chunk_scores"
      ],
      "metadata": {
        "id": "0mSEtYU1W5QY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reranker(bm25results, faresults, wbm25=0.4, wfa=0.6):\n",
        "  bm25results = Normalize(bm25results)\n",
        "  faresults = Normalize(faresults)\n",
        "  all_chunks = {doc.page_content:doc for doc,score in bm25results+faresults}\n",
        "  scores  = {}\n",
        "  for chunk,score in bm25results:\n",
        "    scores[chunk.page_content] = wbm25*score\n",
        "  for chunk,score in faresults:\n",
        "    scores[chunk.page_content] = scores.get(chunk.page_content,0)+wfa*score\n",
        "  finallist=[(all_chunks[page_content],scores[page_content]) for page_content in all_chunks]\n",
        "\n",
        "  return sorted(finallist,key=lambda x:x[1],reverse=True)[:3]"
      ],
      "metadata": {
        "id": "nDDueI80Yu2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "llm = ChatOpenAI(model_name=\"llama3-70b-8192\", openai_api_key='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',temperature=0,openai_api_base=\"https://api.groq.com/openai/v1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjM7vZbGXnNr",
        "outputId": "55998c58-a09f-4b21-972b-2435d553ac96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-90cc83a0db6e>:2: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm = ChatOpenAI(model_name=\"llama3-70b-8192\", openai_api_key='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',temperature=0,openai_api_base=\"https://api.groq.com/openai/v1\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.question_answering import load_qa_chain\n",
        "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
        "query = \"how to set up company email on mobile\"\n",
        "faresult=faiss(query)\n",
        "bm25results=BM25(query,chunks)\n",
        "final_res=reranker(bm25results,faresult)\n",
        "l=[]\n",
        "for doc in final_res:\n",
        "  l.append(doc[0])\n",
        "result = chain.run(input_documents=l,question=query)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "R-kk8gyZuREf",
        "outputId": "96cfd329-e691-43be-b50e-59298e681fe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To set up company email on a mobile device, follow these steps:\n",
            "\n",
            "**Step 1: Ensure Mobile Device Management (MDM) Profile is Installed (if required)**\n",
            "\n",
            "If your company requires MDM for mobile devices, ensure that the profile is installed on your device.\n",
            "\n",
            "**Step 2: Set Up Email Account on Mobile Device**\n",
            "\n",
            "1. Go to the Settings app on your mobile device.\n",
            "2. Select \"Mail\" or \"Email\" (depending on your device's operating system).\n",
            "3. Tap \"Add Account\" or \"Create a new account\".\n",
            "4. Select \"Exchange\" or \"as the account type.\n",
            "5. Enter your company email address and password.\n",
            "6. If prompted, enter the company's email server address (e.g., mail.company.com).\n",
            "7. Select the desired synchronization options (e.g., sync email, contacts, calendar).\n",
            "\n",
            "**Step 3: Configure Email Settings**\n",
            "\n",
            "1. In the email account settings, select the \"Advanced\" or \"Security\" option.\n",
            "2. Ensure that the \"Use SSL/TLS\" or \"Use secure connection\" option is enabled.\n",
            "3. Set the authentication method to \"Username and Password\" or \"Domain\\Username\".\n",
            "4. If prompted, enter your company's email domain (e.g., company.com).\n",
            "\n",
            "**Step 4: Verify Email Account**\n",
            "\n",
            "After completing these steps, your company email should be set up on your mobile device. If you encounter any issues, contact your IT department for assistance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "dft = pd.read_csv('/content/query_sentence_pairs (1).csv')"
      ],
      "metadata": {
        "id": "HVZOt0AoMv-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mknywDvE8cM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import CrossEncoder\n",
        "encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
        "pairs = list(zip(dft[\"Query\"], dft[\"Sentence\"]))\n",
        "scores = encoder.predict(pairs)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ObMaaFeV_2Pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_embeddings = np.array(embeddings.embed_documents(dft[\"Query\"].tolist()))\n",
        "sentence_embeddings = np.array(embeddings.embed_documents(dft[\"Sentence\"].tolist()))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "G_6XaxQq-E5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_embeddings = np.concatenate((query_embeddings, sentence_embeddings), axis=1)"
      ],
      "metadata": {
        "id": "krT1q7NL-qnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(768, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(128, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(64, 1),\n",
        ")\n",
        "\n",
        "X=torch.tensor(combined_embeddings).float()\n",
        "y=torch.tensor(scores).float()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "crite=nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epo in range(10):\n",
        "  batchsize = 8\n",
        "  model.train()\n",
        "\n",
        "  for i in range(0,len(X_train),batchsize):\n",
        "    xb = X_train[i:i+batchsize]\n",
        "    yb = y_train[i:i+batchsize]\n",
        "    optimizer.zero_grad()\n",
        "    preds = model(xb).squeeze(1)\n",
        "    loss = crite(preds, yb)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    predictions = model(X_train).squeeze(1).numpy()\n",
        "    true_values = y_train.numpy()\n",
        "    r2 = r2_score(true_values, predictions)\n",
        "    print(r2)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    predictions = model(X_test).squeeze(1).numpy()\n",
        "    true_values = y_test.numpy()\n",
        "    r2 = r2_score(true_values, predictions)\n",
        "    print(r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hV_0rUKIAmmC",
        "outputId": "30906fde-d659-4dd3-b76f-bd471cb89aa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9572993516921997\n",
            "0.8724011182785034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/synthetic_knowledge_items.csv')\n",
        "from langchain_community.document_loaders import DataFrameLoader\n",
        "doc_loader = DataFrameLoader(df.tail(90), page_content_column=\"ki_text\")\n",
        "doc = doc_loader.load()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "376xKCNGGRc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000)\n",
        "chunks = text_splitter.split_documents(doc)"
      ],
      "metadata": {
        "id": "OstbCq4HfpZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x,y=[],[]\n",
        "for chunk in chunks:\n",
        "  x.append(chunk.metadata.get('ki_topic'))\n",
        "  y.append(chunk.page_content)\n",
        "\n",
        "pairs=list(zip(x,y))\n",
        "scores = encoder.predict(pairs)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "pmnaqSDZZENL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_queryembed = np.array(embeddings.embed_documents(x))\n",
        "data_sentenceembed = np.array(embeddings.embed_documents(y))\n",
        "data_combinedembed = np.concatenate((data_queryembed, data_sentenceembed), axis=1)"
      ],
      "metadata": {
        "id": "60qK4CXCI5t0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''model = nn.Sequential(\n",
        "    nn.Linear(768, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(128, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(64, 1),\n",
        ")'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "89msITMlwplf",
        "outputId": "72534b65-c924-4ad9-90c7-3b5307e7490b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'model = nn.Sequential(\\n    nn.Linear(768, 128),\\n    nn.ReLU(),\\n    nn.Dropout(0.5),\\n    nn.Linear(128, 64),\\n    nn.ReLU(),\\n    nn.Dropout(0.5),\\n    nn.Linear(64, 1),\\n)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=torch.tensor(data_combinedembed).float()\n",
        "y=torch.tensor(scores).float()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "crite=nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "u05vaARmKKJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epo in range(20):\n",
        "  batchsize = 8\n",
        "  model.train()\n",
        "\n",
        "  for i in range(0,len(X_train),batchsize):\n",
        "    xb = X_train[i:i+batchsize]\n",
        "    yb = y_train[i:i+batchsize]\n",
        "    optimizer.zero_grad()\n",
        "    preds = model(xb).squeeze(1)\n",
        "    loss = crite(preds, yb)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "i1QHvuuvKwFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    predictions = model(X_test).squeeze(1).numpy()\n",
        "    true_values = y_test.numpy()\n",
        "    r2 = r2_score(true_values, predictions)\n",
        "    print(r2)"
      ],
      "metadata": {
        "id": "GFrYpmaLMRm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nnreranker(bm25results,faresults,query):\n",
        "  all_chunks = {doc.page_content:doc for doc,score in bm25results+faresults}\n",
        "  order=[]\n",
        "  for chunk in all_chunks:\n",
        "    data_queryembed = np.array(embeddings.embed_documents([query]))\n",
        "    data_sentenceembed = np.array(embeddings.embed_documents(chunk))\n",
        "    combined_embeddings = np.concatenate((query_embeddings, sentence_embeddings), axis=1)\n",
        "    X=torch.tensor(combined_embeddings).float()\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      predictions = model(X)[0]\n",
        "    order.append((all_chunks[chunk],predictions))\n",
        "  return sorted(order,key=lambda x:x[1],reverse=True)[:3]"
      ],
      "metadata": {
        "id": "-9zp5wAtvmid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sRGM0mFk6zOW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}